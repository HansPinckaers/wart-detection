{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '1'\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import pudb\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import fnmatch\n",
    "import random\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "\n",
    "sys.path.append('../3_svm_model/')\n",
    "sys.path.append('../2_compare_detectors/')\n",
    "\n",
    "from train import filenames_for_participants\n",
    "from divide import divide_in\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images for0\n",
      "Size of the original train data: (21691, 64, 64, 3)\n",
      "loading images for1\n",
      "Size of the original train data: (21270, 64, 64, 3)\n",
      "loading images for2\n",
      "Size of the original train data: (21500, 64, 64, 3)\n",
      "loading images for3\n",
      "Size of the original train data: (21940, 64, 64, 3)\n",
      "loading images for4\n",
      "Size of the original train data: (21139, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "for kfold in range(5):\n",
    "    print \"loading images for\" + str(kfold)\n",
    "    # get all participants in training set to create a per participant ..\n",
    "    # validation and test set.\n",
    "    participants = []\n",
    "    for root, dirnames, filenames in os.walk(\"../../images/train_set\"):\n",
    "        for filename in fnmatch.filter(filenames, '*.png'):\n",
    "            part = filename.split(\" - \")[0]\n",
    "            if part not in participants:\n",
    "                participants.append(part)\n",
    "    participants.sort()\n",
    "\n",
    "    # divide the participants in 5 parts (same as we used in the SVM k-fold \n",
    "    # validation), then loop through the participants and get the filenames\n",
    "    # Subsequently the images are loaded and put into folds (k=5)\n",
    "    participants_sliced = divide_in(participants, 5)\n",
    "    folds = []\n",
    "    for p in participants_sliced:\n",
    "        filenames_pos, filenames_neg = \\\n",
    "            filenames_for_participants(p,\n",
    "                os.walk(\"../../images/train_set\"), cream=True)\n",
    "        filenames_pos_mining, filenames_neg_mining = \\\n",
    "            filenames_for_participants(p,\n",
    "                os.walk(\"../../images/classified_mining\"), cream=True)\n",
    "        filenames_pos = filenames_pos + filenames_pos_mining\n",
    "        filenames_neg = filenames_neg + filenames_neg_mining\n",
    "        filenames_pos.sort()\n",
    "        filenames_neg.sort()\n",
    "\n",
    "        images_pos = []\n",
    "        images_neg = []\n",
    "\n",
    "        for i, filename in enumerate(filenames_pos):\n",
    "            img = cv2.imread(filename)\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            images_pos.append(img)\n",
    "        for i, filename in enumerate(filenames_neg):\n",
    "            img = cv2.imread(filename)\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "            images_neg.append(img)\n",
    "\n",
    "        folds.append([images_pos, images_neg])\n",
    "\n",
    "    # Just like in the SVM training take the first fold as validation set (here 'test')\n",
    "    train_set_pos = []\n",
    "    train_set_neg = []\n",
    "    test_set_pos = []\n",
    "    test_set_neg = []\n",
    "    for j, f_ in enumerate(folds):\n",
    "        if j == kfold:\n",
    "            test_set_pos = folds[j][0]\n",
    "            test_set_neg = folds[j][1]\n",
    "        else:\n",
    "            train_set_pos += folds[j][0]\n",
    "            train_set_neg += folds[j][1]\n",
    "\n",
    "    # Create a array with labels and concatenate the positive and negative images\n",
    "    # in one array (here wrongly called \"hists\"\n",
    "    labels_train = np.zeros(len(train_set_pos)+len(train_set_neg))\n",
    "    labels_train[len(train_set_pos):] = 1\n",
    "\n",
    "    # One-hot the label array ([0, 1, 0] -> [[1, 0], [0, 1], [1, 0]]\n",
    "    # For training this is done in the training loop\n",
    "    labels_train = (labels_train[:,None] == np.arange(2)).astype(float)\n",
    "\n",
    "    hists_train = np.concatenate((train_set_pos, train_set_neg))\n",
    "    print \"Size of the original train data: \" + str(hists_train.shape)\n",
    "\n",
    "    # Do the same for test set, and normalize the test set\n",
    "    # Normalization of the training set is done after augmentation in the \n",
    "    # training loop.\n",
    "    labels_test = np.zeros(len(test_set_pos)+len(test_set_neg))\n",
    "    labels_test[len(test_set_pos):] = 1\n",
    "    labels_test = (labels_test[:,None] == np.arange(2)).astype(float)\n",
    "\n",
    "    hists_test = np.concatenate((test_set_pos, test_set_neg))\n",
    "    hists_test = hists_test / 255.0 - 0.5\n",
    "\n",
    "    np.save(\"hists_test_kfold_\" + str(kfold), hists_test)\n",
    "    np.save(\"labels_test_kfold_\"  + str(kfold), labels_test)\n",
    "    np.save(\"hists_train_kfold_\"  + str(kfold), hists_train)\n",
    "    np.save(\"labels_train_kfold_\"  + str(kfold), labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
